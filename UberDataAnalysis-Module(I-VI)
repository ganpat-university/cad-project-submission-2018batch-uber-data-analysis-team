# -*- coding: utf-8 -*-
"""CAD_Project.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1zTWkAJ1ryIZOUGqLrtCOPxInKwmWpfy0
"""

import pandas as pd
import numpy as np

import matplotlib.pyplot as plt
import seaborn as sns

import streamlit as st

uber = pd.read_csv('https://raw.githubusercontent.com/faspy/raw_data/main/trips_data.csv')

st.altair_chart(uber)

uber.info()       # Checking Uber Dataset Basic Details

uber.rename(columns={'City':'city', 'Product Type':'product_type', 'Trip or Order Status':'status', 
                     'Request Time':'request_time', 'Begin Trip Time':'begin_time',                                       # Renaming Columns for ease Access 
                     'Begin Trip Lat':'begin_lat', 'Begin Trip Lng':'begin_lng',                                          # and Normalize Column Names 
                     'Dropoff Time':'dropoff_time', 'Dropoff Lat':'dropoff_lat', 
                     'Dropoff Lng':'dropoff_lng', 'Distance (miles)':'distance_miles', 
                     'Fare Amount':'fare_amount', 'Fare Currency':'fare_currency'}, inplace=True)

sns.scatterplot(x='distance_miles',y='fare_amount',data=uber);                                                             # we have a strong correlation between ‘fare_amount’ and ‘distance_miles’, 
                                                                                                                           # impling that as much you stay on the ride, higher will the fare be.

uber.isnull().sum().sort_values(ascending=False)                                                                           # Checking Existance of Missing Values in dataset

uber[uber.product_type.isnull()]                                                                                           # This column signifies no records into our dataset, Hence Good idea is to drop them.
uber.dropna(subset = ['product_type'], inplace=True)

# Checking categories in product_type column
print(uber.product_type.value_counts())

# Categories reclassification
product_mapping = {'UberX':'UberX','uberX':'UberX','uberX VIP':'UberX','VIP':'UberX','POOL':'Pool','POOL: MATCHED':'Pool','UberBLACK': 'Black',
                   'uberx':'UberX','uberPOOL':'Pool','uberPOOL: MATCHED':'Pool','Pool: MATCHED':'Pool'}

# New categories replacement
uber['product_type'].replace(product_mapping, inplace=True)

# Checking new categories in product_type column
print()
print(uber.product_type.value_counts())                                                                                    # since We found different values referring to the same category. 
                                                                                                                           # We summarized 15 original categories in 5 ones.

# Library for manipulating dates and times
from datetime import datetime
from datetime import timedelta

# Function to convert features to datetime
def convert_date(df, cols):
  for col in cols:
    df[col] = df[col].apply(lambda x:x.replace(' +0000 UTC', ''))
    df[col] = pd.to_datetime(df[col])
  return df

# Applying date_convertion function to date features                                                                      # our dates features are in object data types, 
uber = convert_date(uber, ['request_time', 'begin_time', 'dropoff_time'])                                                 # so we need to convert them into datetime format.

uber['year'] = uber.request_time.map(lambda x: datetime.strftime(x,"%Y"))
uber['month'] = uber.request_time.map(lambda x: datetime.strftime(x,"%b"))                                                # Now, let’s break down <request_time> feature 
uber['weekday'] = uber.request_time.map(lambda x: datetime.strftime(x,"%a"))                                              # into different date parts.
uber['time'] = uber.request_time.map(lambda x: datetime.strftime(x,"%H:%M"))
print(uber['year']+'   '+uber['month']+'   '+uber['weekday']+'   '+uber['time'])

uber['distance_in_km'] = round(uber.distance_miles*1.60934, 2)                                                            # Converting Distance in Km from Miles
uber['amount_per_km'] = round(uber.fare_amount/uber.distance_in_km, 2)                                                    # Getting per Km Fare from total distance Travelled
print(uber['distance_in_km'])
print(uber['amount_per_km'])

# let us now check how much time (in minutes) I usually waited for Uber cars to arrive at my destination.
uber['uber_requested_time'] = uber.begin_time - uber.request_time
uber['uber_requested_time'] = uber['uber_requested_time'].apply(lambda x:round(x.total_seconds()/60, 1))
print(uber['uber_requested_time'])

# Similarly let us check how much time (in minutes) was spent on each trip.
uber['trip_duration'] = uber.dropoff_time - uber.begin_time
uber['trip_duration'] = uber['trip_duration'].apply(lambda x:round(x.total_seconds()/60, 1))
print(uber['trip_duration'])

"""## **MODULE I : HOW MANY TRIPS UBER COMPLETED OVER THE YEARS**"""

# MODULE I : HOW MANY TRIPS UBER COMPLETED OVER THE YEARS
completed_trips = uber[(uber.status!='CANCELED')&(uber.status!='DRIVER_CANCELED')]

print("Total Completed Trips : ", completed_trips.status.count())
print(completed_trips.year.value_counts().sort_index(ascending=True))
sns.countplot(data=completed_trips, x='year', order=['2016','2017','2018','2019','2020','2021'], palette='bright')

"""# **MODULE II : HOW MANY TRIPS OF UBER WERE COMPLETED OR CANCELED**"""

# How many trips of Uber were completed or canceled?
print('Total Trips : ', uber.status.count())
print(round(uber.status.value_counts()/uber.status.size*100, 1))

sns.countplot(data=uber, x='year', order=['2016','2017','2018','2019','2020','2021'], hue='status', palette='bright')

"""# **MODULE III : HEATMAP OF WHERE MOST OF UBER DROP-OFFS OCCURRED**
# **[Using - Folium Python Library]**
"""

# HEATMAP OF WHERE MOST OF UBER DROP-OFFS OCCURRED [Library - folium]
# Folium help people visualize geospatial data
import folium
from folium import plugins

coordinates = []
for lat,lng in zip(completed_trips.dropoff_lat.values, completed_trips.dropoff_lng.values):
  coordinates.append([lat, lng])

map = folium.Map(
    location = [-23.5489,-46.6388],         # Location of City : 'Sao Paulo'
    tiles = 'cartodbpositron',
    zoom_start = 7,
    width = '100%',
    height = '100%',
    control_scale = True)

map.add_child(plugins.HeatMap(coordinates))
map

"""# **MODULE IV : WHICH PRODUCT OF UBER IS USUALLY CHOOSEN BY CUSTOMER**"""

# WHICH PRODUCT OF UBER IS USUALLY CHOOSEN BY CUSTOMER
pro_type_uber = pd.Series(completed_trips.product_type.value_counts().sort_index(ascending=False))
# Transforming series in dataframe
df = pd.DataFrame(pro_type_uber)
# Including new column with trips portion
df['%'] = (completed_trips.product_type.value_counts().sort_index(ascending=False)/completed_trips.product_type.size*100).round(1)
#Renaming columns labels
df.rename(columns={'product_type':'Total Rides'}, inplace=True)
print(df)
# Plotting product types count
completed_trips['product_type'].value_counts().plot(kind='bar');

"""# **MODULE V : FIND OUT AVERAGE FARE, DISTANCE, AMOUNT & TIME SPENT ON EACH RIDES**"""

# FIND OUT AVERAGE FARE, DISTANCE, AMOUNT & TIME SPENT ON EACH RIDES
print('Average. Fare:', round(completed_trips.fare_amount.mean(),1),'BRL')
print('Average Distance:',round(completed_trips.distance_in_km.mean(),1),'km')
print('Average Fare/Km:',round(completed_trips.fare_amount.sum()/completed_trips.distance_in_km.sum(),1),'BRL/km')
print('Average Time Spent on Trips:',round(completed_trips.trip_duration.mean(),1),'minutes')
print('')
print('Total fare amount:', round(completed_trips.fare_amount.sum(),1),'BRL')
print('Total distance:',round(completed_trips.distance_in_km.sum(),1),'km')
print('Total time spent on trips:',round(completed_trips.trip_duration.sum()/60,1),'hours')

"""# **MODULE VI : FINDING WHICH WEEKDAY IS HAVING THE HIGHEST AVERAGE FARES/KM RIDDEN**"""

# FINDING WHICH WEEKDAY IS HAVING THE HIGHEST AVERAGE FARES/KM RIDDEN
amount_table = completed_trips.pivot_table(values='fare_amount',aggfunc='sum',columns='weekday', index='year').round(1)
column_order = ['Mon','Tue','Wed','Thu','Fri','Sat','Sun']
amount_table = amount_table.reindex(column_order, axis=1)

distance_table = completed_trips.pivot_table(values='distance_in_km',aggfunc='sum',columns='weekday', index='year').round(1)
distance_table = distance_table.reindex(column_order, axis=1)

(amount_table/distance_table).round(1)


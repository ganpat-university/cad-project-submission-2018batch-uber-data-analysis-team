# -*- coding: utf-8 -*-
"""Copy of CAD_Project.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1Tfrf-lN26w8ZuWbwrPplFh9OAD02_ApT
"""

import pandas as pd
import numpy as np

import matplotlib.pyplot as plt
import seaborn as sns

from google.colab import drive
drive.mount('/content/drive')

uber = pd.read_csv('/content/drive/MyDrive/ML Lab Dataset/UberDataset.csv', delimiter=None)
uber

uber.info()                                                                                           # Checking Uber Dataset Basic Details

uber.isnull().sum().sort_values(ascending=False)                                                      # Checking Existance of Missing Values in dataset

uber.rename(columns={'Date/Time':'date_time'}, inplace=True)

# Library for manipulating dates and times
from datetime import datetime
from datetime import timedelta

# Function to convert features to datetime
def convert_date(df, cols):
  for col in cols:
    df[col] = df[col].apply(lambda x:x.replace(' +0000 UTC', ''))
    df[col] = pd.to_datetime(df[col])
  return df

# Applying date_convertion function to date features                                                  # our dates features are in object data types, 
uber = convert_date(uber, ['date_time'])                                                              # so we need to convert them into datetime format.

uber['year'] = uber.date_time.map(lambda x: datetime.strftime(x,"%Y"))
uber['month'] = uber.date_time.map(lambda x: datetime.strftime(x,"%b"))                               # Now, let’s break down <request_time> feature 
uber['weekday'] = uber.date_time.map(lambda x: datetime.strftime(x,"%a"))                             # into different date parts.
uber['time'] = uber.date_time.map(lambda x: datetime.strftime(x,"%H:%M"))
print(uber['year']+'   '+uber['month']+'   '+uber['weekday']+'   '+uber['time'])

week_day = uber.pivot_table(index=['weekday'], values='Base', aggfunc='count')                        # No. of Location Travelled by Customer on Particular Day of Week
week_day.head()                                                                                       # for the Base Location Available

sns.scatterplot(x='month',y='Base',data=uber);                                                        # we have a strong correlation between ‘Weekday’ and ‘Base’, 
                                                                                                      # impling that as customer on the day, travelled to which Base Centre.

                                            """## **MODULE I : HOW MANY TRIPS UBER COMPLETED OVER THE MONTHS OF 2014**"""

# MODULE I : HOW MANY TRIPS UBER COMPLETED OVER THE YEARS

print("Total Completed Trips : ", uber.weekday.count())
print(uber.month.value_counts().sort_index(ascending=True))
sns.countplot(data=uber, x='month',order=['Apr', 'May', 'Jun', 'Jul', 'Aug', 'Sep'], palette='bright')

                                          """# **MODULE II :  Total Number Of Rides for The Weekdays for Each Individual Month**"""

# Commented out IPython magic to ensure Python compatibility.
# Total Number Of Rides for The Weekdays for Each Individual Month
import seaborn as sns
import matplotlib.pyplot as plt
from matplotlib import cm
# %matplotlib inline

daily_rides = uber.groupby(['month','weekday'])['Base'].count()
daily_rides = daily_rides.reset_index()
daily_rides.head()

fig = plt.figure(figsize=(12,6))
sns.set_style('darkgrid')

ax = sns.pointplot(x="weekday", y="Base", hue="month", data=daily_rides)
handles,labels = ax.get_legend_handles_labels()

ax.set_xlabel('Day of Week', fontsize = 15)
ax.set_ylabel('Total Uber Pickups', fontsize = 15)
ax.set_title('Total Number of Pickups for Each Weekday per Month (April-September 2014)', fontsize=16)
ax.tick_params(labelsize = 8)
ax.legend(handles,labels,loc=0, title='Months', prop={'size':10})
ax.get_legend().get_title().set_fontsize('8')
plt.show()

                                    """# **MODULE III : Count The Rides For Every Hour Of Everyday In The Months**"""

uber['time'] =  uber['date_time'].dt.time
uber['hour'] = uber['date_time'].dt.hour
uber.head()

hourly_ride = uber.groupby(['month','hour','weekday'])['Base'].count()
hourly_ride = hourly_ride.reset_index()
hourly_ride = hourly_ride.rename(columns = {'Base':'RideCount'})
hourly_ride.head()

"""**For Eg. Let's Pick the Month of August**"""

aug_hourly_data = hourly_ride[hourly_ride.month == 'Aug']

fig = plt.figure(figsize=(12,6))
sns.set_style('darkgrid')

ax = sns.pointplot(x="hour", y="RideCount", hue="weekday", data=aug_hourly_data)
handles,labels = ax.get_legend_handles_labels()
ax.set_xlabel('Hour of Day', fontsize = 15)
ax.set_ylabel('Uber Pickups', fontsize = 15)
ax.set_title('Total Hourly Uber Pickups By Day of the Week in NYC (August 2014)', fontsize=16)
ax.tick_params(labelsize = 8)
ax.legend(handles,labels,loc=0, title="Days", prop={'size':10})
ax.get_legend().get_title().set_fontsize('8')
plt.show()

                                      """# **MODULE IV : Hourly Averages of Pickups Each Weekday**"""

weekday_hourly_avg = hourly_ride.groupby(['weekday','hour'])['RideCount'].mean()
weekday_hourly_avg = weekday_hourly_avg.reset_index()
weekday_hourly_avg = weekday_hourly_avg.rename(columns = {'RideCount':'AverageRides'})
weekday_hourly_avg = weekday_hourly_avg.sort_index()
weekday_hourly_avg.head()

weekday_hourly_avg.weekday.value_counts()

                                                """# **MODULE V : Distribution of Uber pickups Based on the Bases**"""

uber.Base.value_counts()

base_names = {"Base": {'B02617':'Weiter', 'B02598':'Hinter','B02682':'Schmecken','B02764':'Danach-NY','B02512':'Unter'}}
uber_bases = uber.copy()
uber_bases.replace(base_names, inplace=True)
uber_bases.head()

plt.hist(x=uber_bases['Base'], density=1, color='green')
plt.show()

                                            """# **MODULE VI : Heat Map of Total Pickups over the 6 Months**"""

pip install -q https://github.com/matplotlib/basemap/archive/master.zip

pip install -q pyproj==1.9.6

from mpl_toolkits.basemap import Basemap

west, south, east, north = -74.26, 40.50, -73.70, 40.92

fig = plt.figure(figsize=(14,10))

ax = fig.add_subplot(111)

m = Basemap(projection='merc', llcrnrlat=south, urcrnrlat=north, llcrnrlon=west, urcrnrlon=east, lat_ts=south, resolution='i')

x, y = m(uber['Lon'].values, uber['Lat'].values)
m.hexbin(x, y, gridsize=1000, bins='log', cmap='Oranges');

"""# **MODULE VII : No. of Pickups that occur within 50 meters on August 2014**"""

pip install mplleaflet

from sklearn.cluster import DBSCAN
from geopy.distance import great_circle
from shapely.geometry import MultiPoint

def get_hot_spots(max_distance, min_cars, ride_data):
  coords = ride_data[['Lat', 'Lon']].to_numpy()
  kms_per_radian = 6371.0088
  epsilon = max_distance / kms_per_radian

  db = DBSCAN(eps=epsilon, min_samples=min_cars, algorithm='ball_tree', metric='haversine').fit(np.radians(coords))
    
  cluster_labels = db.labels_
  num_clusters = len(set(cluster_labels))
  clusters = pd.Series([coords[cluster_labels == n] for n in range(num_clusters)])
    
  print('Number of clusters: {}'.format(num_clusters))

  lat = []
  lon = []
  num_members = []
    
  for ii in range(len(clusters)):
    if clusters[ii].any():
      lat.append(MultiPoint(clusters[ii]).centroid.x)
      lon.append(MultiPoint(clusters[ii]).centroid.y)
      num_members.append(len(clusters[ii]))
            
  hot_spots = [lon,lat,num_members]
  return hot_spots

ride_data = uber_bases.loc[(uber_bases['month'] == 'Aug') & (uber_bases['hour'] > 15)]
print(ride_data)
max_distance = 0.05
min_pickups = 25
hot_spots = get_hot_spots(max_distance, min_pickups, ride_data)

"""**From the data, there are 423 cluster all around NYC meeting the criteria.** 

**Let’s plot it out to visualize it.**
"""

import mplleaflet

fig = plt.figure(figsize=(8,8))
ax = fig.add_subplot(111)

color_scale = np.log(hot_spots[2])

plt.scatter(hot_spots[0], hot_spots[1],s=80,c=color_scale,cmap=cm.autumn)
mplleaflet.display()

